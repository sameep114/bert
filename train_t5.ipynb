{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train t5",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVV+TOKK5OPQ9X2ickkstH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7191fcdf24714337bb3c73cfa0ef0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d763114a597449a881852670a993a8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d5e9f7431274130b1b6914c40e75080",
              "IPY_MODEL_a2827442fb7c45c9b31c5d8f8a90f617"
            ]
          }
        },
        "7d763114a597449a881852670a993a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d5e9f7431274130b1b6914c40e75080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_26d4ad09ea8d44bba259271b08a48b6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.04MB of 0.04MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b996c5284ab46099bed11e4cc60b0ee"
          }
        },
        "a2827442fb7c45c9b31c5d8f8a90f617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a41fd94d9bad4ae6919be1b91537d29e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f837e9403075485cbbc5d529a9b4f734"
          }
        },
        "26d4ad09ea8d44bba259271b08a48b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b996c5284ab46099bed11e4cc60b0ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a41fd94d9bad4ae6919be1b91537d29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f837e9403075485cbbc5d529a9b4f734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameep114/bert/blob/master/train_t5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG_Ao2ooNZri",
        "outputId": "481ecc44-80f7-4e10-cceb-6cac78aed92f"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3MB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 13.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 20.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 23.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/93/7c/bf3cba8513f02c92fff0f0dab49846f1aa3da93c71fb4de7f34f501d15f0/wandb-0.10.11-py2.py3-none-any.whl\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 5.5MB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/sentry-sdk/\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 133kB 43.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 39.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mndH8DfhNfqF"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to_JAf6pOHvQ"
      },
      "source": [
        "# check working gpu \n",
        "# needed to be coded"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvFYpm5hOQWm"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohG76PLUOp8r",
        "outputId": "e247e581-7413-4b65-e16d-3a06088c209d"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQjwOHDZPN4Q",
        "outputId": "3414c061-7340-4a44-9bce-869eae08d45b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LngVGCJO8uV"
      },
      "source": [
        "Preparing the dataset for data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPSzhcrWQPtq"
      },
      "source": [
        "#creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it into neural network later for finetuning and prepare for predictions\n",
        "class Customdataset(Dataset):\n",
        "\n",
        "  def __init__(self,dataframe, tokenizer, source_len, summ_len):\n",
        "    self.tokenozer=tokenizer\n",
        "    self.data=data\n",
        "    self.source_len= source_len\n",
        "    self.summ_len=summ_len\n",
        "    self.text=self.data.text\n",
        "    self.ctext=self.data.ctext\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "  def __getitem__(self ,index):\n",
        "    ctext=str(self.ctext[index])\n",
        "    ctext=' '.join(ctext.split())\n",
        "\n",
        "    text=str(self.ctext[index])\n",
        "    text=' '.join(text.split())\n",
        "    \n",
        "\n",
        "    source=self.tokenizer.batch_encode_plus([ctext],max_length=self.source_len,pad_to_max_length=True, return_tensors='pt')\n",
        "    source=self.tokenizer.batch_encode_plus([text],max_length=self.summ_len,pad_to_max_length=True, return_tensors='pt')\n",
        "\n",
        "    source_ids = source['input_ids'].squeeze()\n",
        "    source_mask = source['attention_mask'].squeeze()\n",
        "    target_ids = target['input_ids'].squeeze()\n",
        "    target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "    return {\n",
        "      'source_ids': source_ids.to(dtype=torch.long), \n",
        "      'source_mask': source_mask.to(dtype=torch.long), \n",
        "      'target_ids': target_ids.to(dtype=torch.long),\n",
        "      'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxCCH3TNVBPB"
      },
      "source": [
        "Fine Tuning The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij2sK4FVVHDQ"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSHPV8V4VluA"
      },
      "source": [
        "\"\"validating the Perfomance model\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sThkFK8sVt-A"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psKQNG2KV1TR"
      },
      "source": [
        "Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803,
          "referenced_widgets": [
            "7191fcdf24714337bb3c73cfa0ef0467",
            "7d763114a597449a881852670a993a8a",
            "2d5e9f7431274130b1b6914c40e75080",
            "a2827442fb7c45c9b31c5d8f8a90f617",
            "26d4ad09ea8d44bba259271b08a48b6e",
            "6b996c5284ab46099bed11e4cc60b0ee",
            "a41fd94d9bad4ae6919be1b91537d29e",
            "f837e9403075485cbbc5d529a9b4f734"
          ]
        },
        "id": "Wqv-HdG8WE9P",
        "outputId": "ee1e20d3-9d85-446b-caa5-3be78667e2b8"
      },
      "source": [
        "def main():\n",
        "    # WandB – Initialize a new run\n",
        "    wandb.init(project=\"transformers_tutorials_summarization\")\n",
        "\n",
        "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "    # Defining some key variables that will be used later on in the training  \n",
        "    config = wandb.config          # Initialize config\n",
        "    config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "    config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "    config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n",
        "    config.VAL_EPOCHS = 1 \n",
        "    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "    config.SEED = 42               # random seed (default: 42)\n",
        "    config.MAX_LEN = 512\n",
        "    config.SUMMARY_LEN = 150 \n",
        "\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(config.SEED) # pytorch random seed\n",
        "    np.random.seed(config.SEED) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # tokenzier for encoding the text\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
        "    \n",
        "\n",
        "    # Importing and Pre-Processing the domain data\n",
        "    # Selecting the needed columns only. \n",
        "    # Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "    df = pd.read_csv('/content/drive/MyDrive/Datasets/nepali_news_dataset_20_categories_large/Agriculture/1.txt',error_bad_lines=False)\n",
        "    # df = df[['text','ctext']]\n",
        "    df.ctext = 'summarize: ' + df\n",
        "    print(df.head())\n",
        "\n",
        "    \n",
        "    # Creation of Dataset and Dataloader\n",
        "    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "    train_size = 0.8\n",
        "    train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "    val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    print(\"FULL Dataset: {}\".format(df.shape))\n",
        "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    val_params = {\n",
        "        'batch_size': config.VALID_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "    \n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"google/t5-small\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # Log metrics with wandb\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    # Training loop\n",
        "    print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "    for epoch in range(config.TRAIN_EPOCHS):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "    # Saving the dataframe as predictions.csv\n",
        "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "    for epoch in range(config.VAL_EPOCHS):\n",
        "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "        final_df.to_csv('./models/predictions.csv')\n",
        "        print('Output Files generated for review')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1h96xer2) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 5796<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7191fcdf24714337bb3c73cfa0ef0467",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20201121_110228-1h96xer2/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20201121_110228-1h96xer2/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">worthy-tree-6</strong>: <a href=\"https://wandb.ai/sameep114/transformers_tutorials_summarization/runs/1h96xer2\" target=\"_blank\">https://wandb.ai/sameep114/transformers_tutorials_summarization/runs/1h96xer2</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1h96xer2). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.11<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">morning-sea-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sameep114/transformers_tutorials_summarization\" target=\"_blank\">https://wandb.ai/sameep114/transformers_tutorials_summarization</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sameep114/transformers_tutorials_summarization/runs/14xx4o36\" target=\"_blank\">https://wandb.ai/sameep114/transformers_tutorials_summarization/runs/14xx4o36</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201121_111224-14xx4o36</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  काठमाडौंमा पहिलो पटक स्ट्रबेरीको व्यवसायिक खेती सुरु भएको छ । एक दशकसम्म इजरायली कृषि फार्ममा बसेर काम गरेका श्रीकृष्ण अधिकारीले तारकेश्वर नगरपालिका ४ गोलढुंगामा उत्पादन सुरु गरेका हुन्।\n",
            "0  यसअघि स्ट्रबेरी नुवाकोटमा गरिँदै आएको थियो। अध...                                                                                                                                        \n",
            "1  बीस–पच्चीस वर्षअघि ककनीमा जाइटी भन्ने संस्थाले...                                                                                                                                        \n",
            "2  अधिकारीको फर्ममा अहिले स्ट्रबेरी फल्न सुरु गरे...                                                                                                                                        \n",
            "3  विभिन्न शुभ कार्यहरुमा समेत स्ट्रबेरीलाई प्याक...                                                                                                                                        \n",
            "4  विदेशमा लामो समयसम्म काम गरेकोले पनि आफूले स्व...                                                                                                                                        \n",
            "FULL Dataset: (6, 1)\n",
            "TRAIN Dataset: (5, 1)\n",
            "TEST Dataset: (1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 4: expected 1 fields, saw 2\\nSkipping line 6: expected 1 fields, saw 4\\nSkipping line 8: expected 1 fields, saw 3\\nSkipping line 9: expected 1 fields, saw 2\\n'\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cafbf9d89f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-cafbf9d89f00>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtraining_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mval_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z9aF1Jmbo93"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}